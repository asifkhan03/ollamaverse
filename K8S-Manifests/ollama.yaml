# ================= smollm2 =================
apiVersion: v1
kind: Service
metadata:
  name: ollama-smollm2
  namespace: aiops
  labels:
    app: ollama-smollm2
spec:
  selector:
    app: ollama-smollm2
  ports:
    - port: 11434
      targetPort: 11434
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-smollm2
  namespace: aiops
  labels:
    app: ollama-smollm2
spec:
  # priorityClassName: tracemypods-pL1
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: ollama-smollm2
  template:
    metadata:
      labels:
        app: ollama-smollm2
    spec:
      containers:
        - name: ollama
          image: ollama/ollama
          ports:
            - containerPort: 11434
          env:
            - name: OLLAMA_MODEL
              value: "smollm2:135m-instruct-q8_0" # https://ollama.com/library/smollm2/tags
          volumeMounts:
            - name: ollama-models
              mountPath: /root/.ollama
          # resources:
          #   requests:
          #     memory: "500Mi"
          #     cpu: "500m"
          #   limits:
          #     memory: "1024Mi"
          #     cpu: "1Gi"
          command: ["/bin/sh"]
          args:
            - -c
            - |
              ollama serve & 
              sleep 3 && ollama run $OLLAMA_MODEL && wait
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  if ollama run $OLLAMA_MODEL; then
                    exit 0
                  else
                    exit 1
                  fi
            initialDelaySeconds: 60
            periodSeconds: 10
            failureThreshold: 10
      volumes:
        - name: ollama-models
          emptyDir: {}
# ================= TINYLLMA =================
---
apiVersion: v1
kind: Service
metadata:
  name: ollama-tinyllama
  namespace: aiops
  labels:
    app: ollama-tinyllama
spec:
  selector:
    app: ollama-tinyllama
  ports:
    - port: 11434
      targetPort: 11434
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-tinyllama
  namespace: aiops
  labels:
    app: ollama-tinyllama
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: ollama-tinyllama
  template:
    metadata:
      labels:
        app: ollama-tinyllama
    spec:
      containers:
        - name: ollama
          image: ollama/ollama
          ports:
            - containerPort: 11434
          env:
            - name: OLLAMA_MODEL
              value: "tinyllama:latest"
          volumeMounts:
            - name: ollama-models
              mountPath: /root/.ollama
          # resources:
          #   requests:
          #     memory: "500Mi"
          #     cpu: "500m"
          #   limits:
          #     memory: "1024Mi"
          #     cpu: "1"
          command: ["/bin/sh"]
          args:
            - -c
            - |
              ollama serve & 
              sleep 3 && ollama run $OLLAMA_MODEL && wait
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - |
                  if ollama run $OLLAMA_MODEL; then
                    exit 0
                  else
                    exit 1
                  fi
            initialDelaySeconds: 60
            periodSeconds: 10
            failureThreshold: 10
      volumes:
        - name: ollama-models
          emptyDir: {}